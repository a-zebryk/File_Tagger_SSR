{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b4118d",
   "metadata": {},
   "source": [
    "# Service Shop Reports Tagger\n",
    "This Notebook requires SSR_Spacy Model - which can be created using \"SSR_spacy_model\" notebook\n",
    "\n",
    "## Steps\n",
    "1. Load Data\n",
    "2. Clean Text\n",
    "3. Load spacy model, transform clean text into spacy docs\n",
    "4. Get file tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdec2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !pip install \n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install fitz\n",
    "# !pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86ec25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-2.12.1-py3-none-any.whl (222 kB)\n",
      "     -------------------------------------- 222.8/222.8 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-2.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb8b7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import fitz\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy import displacy\n",
    "# from spacy.language import Language\n",
    "# from spacy_langdetect import LanguageDetector\n",
    "\n",
    "\n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "import io\n",
    "\n",
    "from collections import Counter\n",
    "import shutil\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "361bc969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c445375",
   "metadata": {},
   "source": [
    "# 1. Load Data\n",
    "- only pdf files in location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c5e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_file(file):\n",
    "    '''\n",
    "    Input: \n",
    "    - pdf file name/path\n",
    "    Return: \n",
    "    - string, extracted text from all pages\n",
    "    '''\n",
    "    with fitz.open(file) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "#             text += page.getText()            # get_text\n",
    "            text += page.get_text() \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def load_multiple_files(folder_name):\n",
    "    '''\n",
    "    Input: \n",
    "    - folder_name with pdf files. Folder must be in current working directory\n",
    "    Return: \n",
    "    - 2 lists:list of string, extracted text from all pages and list of file names\n",
    "    '''\n",
    "    texts = []\n",
    "    file_names = []\n",
    "    cur_dir = os.getcwd()\n",
    "    path = f'{cur_dir}\\\\{folder_name}'\n",
    "    os.chdir(path)\n",
    "    file_list = os.listdir()\n",
    "    for file in file_list:\n",
    "        with fitz.open(file) as doc:\n",
    "            text = \"\"\n",
    "            for page in doc:\n",
    "#                 text += page.getText()      # get_text\n",
    "                text += page.get_text()\n",
    "        texts.append(text)\n",
    "        file_names.append(file)\n",
    "    os.chdir(cur_dir)\n",
    "    return texts, file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84f37e",
   "metadata": {},
   "source": [
    "# 2. Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa266f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = text.replace('_', ' ')\n",
    "    text = text.replace('â€¢', ' ')\n",
    "    text = text.replace(' | ', ' ')\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "    text = text.lower().strip()\n",
    "    while \"  \" in text:\n",
    "        text = text.replace(\"  \", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca16f0",
   "metadata": {},
   "source": [
    "# 3. Getting tags using spaCy\n",
    "## 3.1. Serial Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdc5e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OEM SNs\n",
    "\n",
    "def get_sn_oem(doc):\n",
    "    \n",
    "    uniq_sns = []\n",
    "    for token in doc.ents:\n",
    "        if token.label_ == 'SN_OEM':\n",
    "            uniq_sns.append(token.text) \n",
    "    return set(uniq_sns)\n",
    "\n",
    "\n",
    "# exclude short sns\n",
    "def get_sn_oem(doc):\n",
    "    \n",
    "\n",
    "    uniq_sns = []\n",
    "    for token in doc.ents:\n",
    "        if token.label_ == 'SN_OEM' and len(token.text) > 3:\n",
    "            uniq_sns.append(token.text) \n",
    "    return set(uniq_sns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c59b5853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EQ SNs\n",
    "def get_sn_eq(doc):\n",
    "    \n",
    "    uniq_sns = []\n",
    "    for token in doc.ents:\n",
    "        if token.label_ == 'SN_EQ':\n",
    "            uniq_sns.append(token.text) \n",
    "    return set(uniq_sns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3fe30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is classic approach, not using spacy but classic regex\n",
    "\n",
    "def get_sn_classic(text):\n",
    "    \n",
    "    #dzialajace\n",
    "    sns = []\n",
    "    pattern_1 = r'serial\\snumber:?\\s[a-z]{0,3}[0-9]+[a-z]?'\n",
    "    pattern_2 = r's/?n:?\\s[a-z]{0,3}[0-9]+[a-z]?'\n",
    "    pattern_3 = r'matr.\\smacchina:?\\s[a-z]{0,3}[0-9]+[a-z]?'\n",
    "    pattern_4 = r'matricola\\smacchina:?\\s[a-z]{0,3}[0-9]+[a-z]?'\n",
    "    \n",
    "    # urozmaicam\n",
    "    pattern_1 = r'serial\\snumber:?\\s[a-z]{0,4}[#-]?[0-9]+[a-z]?/?[0-9]?'\n",
    "    pattern_2 = r's/?n:?\\s[a-z]{0,4}[#-]?[0-9]+[a-z]?/?[0-9]?'\n",
    "    pattern_3 = r'matr.\\smacchina:?\\s[a-z]{0,4}[#-]?[0-9]+[a-z]?/?[0-9]?'\n",
    "    pattern_4 = r'matricola\\smacchina:?\\s[a-z]{0,4}[#-]?[0-9]+[a-z]?/?[0-9]?'\n",
    "\n",
    "        # urozmaicam\n",
    "    pattern_1 = r'serial\\snumber:?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]{0,2}'\n",
    "    pattern_2 = r's/?n:?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]?'\n",
    "    pattern_3 = r'matr.\\smacchina:?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]?'\n",
    "    pattern_4 = r'matricola\\smacchina:?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]?'\n",
    "    pattern_4 = r'matricola\\smacchina:?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]?'\n",
    "    pattern_5 = r'matricola:?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]?'\n",
    "    pattern_6 = r'serial\\snumber\\smacchina:?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]{0,2}'\n",
    "    pattern_7 = r's/?n\\smacchina:?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]{0,2}'\n",
    "    pattern_8 = r'serial\\sn:?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]{0,2}'\n",
    "    pattern_9 = r'machine\\ss\\.\\sn\\.\\s:?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]{0,2}'\n",
    "    \n",
    "            # urozmaicam z .\n",
    "    pattern_1 = r'serial\\snumber[\\.:]?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]{0,2}'\n",
    "    pattern_2 = r's/?n[\\.:]?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]?'\n",
    "    pattern_3 = r'matr.\\smacchina[\\.:]?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]?'\n",
    "    pattern_4 = r'matricola\\smacchina[\\.:]?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]?'\n",
    "    pattern_4 = r'matricola\\smacchina[\\.:]?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]?'\n",
    "    pattern_5 = r'matricola[\\.:]?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]?'\n",
    "    pattern_6 = r'serial\\snumber\\smacchina[\\.:]?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]{0,2}'\n",
    "    pattern_7 = r's/?n\\smacchina[\\.:]?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]{0,2}'\n",
    "    pattern_8 = r'serial\\sn[\\.:]?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]{0,2}'\n",
    "    pattern_9 = r'machine\\ss\\.\\sn\\.\\s[\\.:]?\\s[a-z0-9]{0,2}[-]?[a-z0-9]{0,4}[#-]?[0-9]+[a-z]{0,3}/?[0-9]{0,2}'\n",
    "    \n",
    "    \n",
    "    match_1 = re.findall(pattern_1, text)\n",
    "    match_2 = re.findall(pattern_2, text)\n",
    "    match_3 = re.findall(pattern_3, text)\n",
    "    match_4 = re.findall(pattern_4, text)\n",
    "    match_5 = re.findall(pattern_5, text)\n",
    "    match_6 = re.findall(pattern_6, text)\n",
    "    match_7 = re.findall(pattern_7, text)\n",
    "    match_8 = re.findall(pattern_8, text)\n",
    "    match_9 = re.findall(pattern_9, text)\n",
    "    \n",
    "    sns = match_1 + match_2 + match_3 + match_4 + match_5 + match_6 + match_7 + match_8 + match_9\n",
    "    \n",
    "    sns_clean = []\n",
    "    if len(sns) > 0:\n",
    "        for x in sns:\n",
    "            # bierzemy wszystko po dwukropku, a ajk nie ma dwukropka to bierzemy split spacja i [-1] - co jesli 2 czlony?\n",
    "            sn = x.split(' ')[-1]\n",
    "            sns_clean.append(sn)\n",
    "    \n",
    "    letters = ['g', 'a', 'v', 'c']\n",
    "    # Typo i mozliwe bledy\n",
    "    sns_clean_2 = []\n",
    "    for x in sns_clean:\n",
    "        if x[:2] == 'go':\n",
    "            x = x.replace('go', 'g0')\n",
    "        elif x[:2] == 'vo':\n",
    "            x = x.replace('vo', 'v0')\n",
    "        elif x[:2] == 'co':\n",
    "            x = x.replace('co', 'c0')\n",
    "        elif x[:2] == 'to':\n",
    "            x = x.replace('to', 't0')\n",
    "        \n",
    "        if x[0] in letters and len(x) == 5 and x[1:].isdigit():\n",
    "            x = x.replace(x[0], x[0] + '0')\n",
    "        \n",
    "        if x[0] == 't' and len(x) == 5:\n",
    "            x = x.replace('t', 'tv')\n",
    "        \n",
    "        if '/' in  x:\n",
    "            sep_nr = []\n",
    "            sep_nr = x.split('/')\n",
    "            x_1 = sep_nr[0]\n",
    "            if len(sep_nr[1]) <= 2:\n",
    "                end = -len(sep_nr[1])\n",
    "                x_2 = sep_nr[0][:end] + sep_nr[1]\n",
    "            else:\n",
    "                x_2 = sep_nr[1]\n",
    "            sns_clean_2.append(x_1)\n",
    "            sns_clean_2.append(x_2)\n",
    "        sns_clean_2.append(x)\n",
    "    \n",
    "    sns_clean_3 = []\n",
    "    for x in sns_clean_2:\n",
    "        sns_clean_3.append(x.replace('o', '0'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return set(sns_clean_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e61fa8",
   "metadata": {},
   "source": [
    "## 3.2. Report Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbb0aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report_date(doc):\n",
    "\n",
    "    uniq_date = []\n",
    "    date = \"\"\n",
    "    for token in doc.ents:\n",
    "        if token.label_ == 'REP_DATE':\n",
    "            uniq_date.append(token.text) \n",
    "#     if len(uniq_date) > 0:\n",
    "#         date = uniq_date[0].split()[1:]\n",
    "#     return date\n",
    "    return uniq_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "894fa05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report_date_2(doc):\n",
    "\n",
    "    uniq_date = []\n",
    "    date = \"\"\n",
    "    for token in doc.ents:\n",
    "        if token.label_ == 'REP_DATE_2':\n",
    "            uniq_date.append(token.text) \n",
    "#     if len(uniq_date) > 0:\n",
    "#         date = uniq_date[0].split()[1:]\n",
    "#     return date\n",
    "    return uniq_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a8950ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(doc):\n",
    "\n",
    "    uniq_date = []\n",
    "    for token in doc.ents:\n",
    "        if token.label_ == 'DATE':\n",
    "            uniq_date.append(token.text)\n",
    "            \n",
    "            if 'copyright' in token.text:\n",
    "                uniq_date.remove(token.text)\n",
    "            if 'fm' in token.text:\n",
    "                uniq_date.remove(token.text)\n",
    "    return uniq_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1978da7",
   "metadata": {},
   "source": [
    "## 3.3. Job Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80f609cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job(doc):\n",
    "\n",
    "    jobs = []\n",
    "    for token in doc.ents:\n",
    "        if token.label_ == 'JOB #':\n",
    "            jobs.append(token.text) \n",
    "    return jobs\n",
    "\n",
    "# full\n",
    "def get_job(doc):\n",
    "\n",
    "    jobs = []\n",
    "    job = ''\n",
    "    for token in doc.ents:\n",
    "        if token.label_ == 'JOB #':\n",
    "            jobs.append(token.text)\n",
    "    if len(jobs) > 0:\n",
    "        job = jobs[0].split()[-1]\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "986638c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dziala na &\n",
    "def get_job(doc):\n",
    "\n",
    "    jobs = []\n",
    "    job = ''\n",
    "    for token in doc.ents:\n",
    "        if token.label_ == 'JOB #':\n",
    "            jobs.append(token.text)\n",
    "    if len(jobs) > 0:\n",
    "        job = jobs[0].split()[-1]\n",
    "        \n",
    "        # Number:42833i472 \n",
    "        if ':' in job:\n",
    "            job = job.split(':')[-1]\n",
    "            \n",
    "        # '2302834,5'\n",
    "        if ',' in job:\n",
    "                str_end = job.split(',')[1]\n",
    "                if len(str_end) <= 2:\n",
    "                    first_number = job.split(',')[0]\n",
    "                    new_number = first_number[:-len(str_end)] + str_end\n",
    "                    job = [first_number, new_number]\n",
    "                    \n",
    "                #2302834,5248727    \n",
    "                else:\n",
    "                    first_number = job.split(',')[0]\n",
    "                    new_number = job.split(',')[1]\n",
    "                    job = [first_number, new_number]\n",
    "        \n",
    "        # 2302641&2302642\n",
    "        if '&' in  job:\n",
    "            first_number = job.split('&')[0]\n",
    "            new_number = job.split('&')[1]\n",
    "            job = [first_number, new_number]\n",
    "        \n",
    "        # '2302834,5'\n",
    "        if '/' in job:\n",
    "                str_end = job.split('/')[1]\n",
    "                if len(str_end) <= 2:\n",
    "                    first_number = job.split('/')[0]\n",
    "                    new_number = first_number[:-len(str_end)] + str_end\n",
    "                    job = [first_number, new_number]\n",
    "                    \n",
    "                #2302834,5248727    \n",
    "                else:\n",
    "                    first_number = job.split('/')[0]\n",
    "                    new_number = job.split('/')[1]\n",
    "                    job = [first_number, new_number]\n",
    "        if '#' in job:\n",
    "            job = job.split('#')[-1]\n",
    "                    \n",
    "    return job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d576d",
   "metadata": {},
   "source": [
    "## 3.4. Type of report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dd9202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report_type(doc):\n",
    "\n",
    "    report = []\n",
    "    for token in doc.ents:\n",
    "        if token.label_ == 'REPORT':\n",
    "            report.append(token.text)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3be4e8",
   "metadata": {},
   "source": [
    "## * Count unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "859de5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_words(text):\n",
    "#     return len(set([x for x in text.replace('.','').split(' ') if x.isalpha()]))   # return unique WORDS\n",
    "    return len(set([x for x in text.replace('.','').split(' ') if x.isalnum()]))  # return unique WORDS and NUMBERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc948dda",
   "metadata": {},
   "source": [
    "# Reading files from multiple sources\n",
    "- Input data is stored on the blade\\\n",
    "\\\\Bhifdnbj4j\\Shared\\File_tagger\\Input_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca922e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\ebryaga\\\\Desktop\\\\Data_lake\\\\1_File_tagger\\\\Notebooks\\\\Doc_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c09296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\\\\Bhifdnbj4j\\Shared\\File_tagger\\Input_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd67a632",
   "metadata": {},
   "source": [
    "## a. ROP without OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee582815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full\n",
    "# texts, files = load_multiple_files('No_scan')\n",
    "# df = pd.DataFrame({'name':files, 'text': texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7be4f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('ROP_saved.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d9da3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'\\\\Bhifdnbj4j\\Shared\\File_tagger\\Input_Data\\ROP_saved.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19cd5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rop = df[df['name'].str.contains('OCR_') == False]\n",
    "df_rop['source'] = 'ROP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18316eb4",
   "metadata": {},
   "source": [
    "## b. OCRed files using Google Vison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b5ca3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gv = pd.read_csv(r'\\\\Bhifdnbj4j\\Shared\\File_tagger\\Input_Data\\23_05_google_vision.csv', index_col=0)\n",
    "df_gv['source'] = 'ROP GV'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd20389",
   "metadata": {},
   "source": [
    "## c. Coll Docu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3b65239",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd = pd.read_csv(r'\\\\Bhifdnbj4j\\Shared\\File_tagger\\Input_Data\\OCR_17_coll_docu.csv', index_col=0)\n",
    "df_cd['source'] = 'Coll Docu 17 CSA GT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316cba65",
   "metadata": {},
   "source": [
    "## d. QSC Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "632e1a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "df_qsc1 = pd.read_csv(r'\\\\Bhifdnbj4j\\Shared\\File_tagger\\Input_Data\\QSC_pdf_1.csv', index_col=0)\n",
    "df_qsc1['source'] = 'QSC'\n",
    "\n",
    "# Part 2\n",
    "df_qsc2 = pd.read_csv(r'\\\\Bhifdnbj4j\\Shared\\File_tagger\\Input_Data\\QSC_pdf_2.csv', index_col=0)\n",
    "df_qsc2['source'] = 'QSC'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a76de6",
   "metadata": {},
   "source": [
    "## e. MERGE all sources into one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d051385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rop.append(df_gv).append(df_cd).append(df_qsc1).append(df_qsc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee471544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].isna() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5eea8",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77757ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446ac3a",
   "metadata": {},
   "source": [
    "### Load spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4e84d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\ebryaga\\OneDrive - Baker Hughes\\File_Tagger\\Notebooks\\F_Tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c11e5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('11_05_ssr_ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c5ace",
   "metadata": {},
   "source": [
    "### Create doc object based on clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28038c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = df['clean_text'].to_list()\n",
    "docs = nlp.pipe(clean_text)\n",
    "docs = list(docs)\n",
    "df['clean_text_doc'] = docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b52b1e",
   "metadata": {},
   "source": [
    "### Retrive tags from text using spacy (SNs classic using regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fefd6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SN_OEM'] = df['clean_text_doc'].apply(get_sn_oem)\n",
    "df['SN_EQ'] = df['clean_text_doc'].apply(get_sn_eq)\n",
    "df['SNs classic'] = df['clean_text'].apply(get_sn_classic)\n",
    "df['report_date'] = df['clean_text_doc'].apply(get_report_date)\n",
    "df['report_date_2'] = df['clean_text_doc'].apply(get_report_date_2)\n",
    "df['date'] = df['clean_text_doc'].apply(get_date)\n",
    "df['job'] = df['clean_text_doc'].apply(get_job)\n",
    "# df['language'] = df['clean_text_doc'].apply(check_sent_lang) #slow, checks if it has any sentance in italian\n",
    "df['report'] = df['clean_text_doc'].apply(get_report_type)\n",
    "df['unique_words'] = df['clean_text'].apply(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651cd64",
   "metadata": {},
   "source": [
    "### Serial Number post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae658bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_typos(x):\n",
    "    x = x.replace('o', '0')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d8da29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_rows = []\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    rows_eq= row['SNs classic'].intersection(row['SN_EQ'])\n",
    "    rows_oem= row['SNs classic'].intersection(row['SN_OEM'])\n",
    "    checked_rows.append(rows_eq.union(rows_oem))\n",
    "\n",
    "df['SN_checked'] = checked_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f030ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_rows_2 = []\n",
    "for i, row in df.iterrows():\n",
    "    if len(row['SN_checked']) == 0:\n",
    "        rows_eq = row['SN_EQ'].union(row['SN_OEM'])\n",
    "        checked_rows_2.append(rows_eq)\n",
    "    else:\n",
    "        checked_rows_2.append({})\n",
    "\n",
    "df['SN_checked_2'] = checked_rows_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "768608cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_eq = []\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    rows_eq= row['SNs classic'].intersection(row['SN_EQ'])\n",
    "    checked_eq.append(rows_eq)\n",
    "\n",
    "\n",
    "df['SN_checked_eq'] = checked_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d951e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_oem = []\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    rows_eq= row['SNs classic'].intersection(row['SN_OEM'])\n",
    "    checked_oem.append(rows_eq)\n",
    "\n",
    "\n",
    "df['SN_checked_oem'] = checked_oem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76627a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sn = []\n",
    "for i, row in df.iterrows():\n",
    "    rows_eq = row['SN_checked'].union(row['SN_checked_2'])\n",
    "    final_sn.append(rows_eq)\n",
    "\n",
    "df['SN_checked_final'] = final_sn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9bec8",
   "metadata": {},
   "source": [
    "### Report type post-processing - standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "619c5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['report'] = df['report'].apply(lambda x: [i.replace('//00', '').replace('//1','') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2751277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_std(x):\n",
    "    rep_std = ''\n",
    "    if len(x) > 0:\n",
    "        if 'condition' in x[0]:\n",
    "            rep_std = 'Condition Report'\n",
    "        if 'final' in x[0]:\n",
    "            rep_std = 'Final Report'\n",
    "        if 'preliminar' in x[0]:\n",
    "            rep_std = 'Preliminary Report'\n",
    "        if 'inspection' in x[0]:\n",
    "            rep_std = 'Inspection Report'\n",
    "    else:\n",
    "        rep_std = 'Other'\n",
    "    return rep_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73c7d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['report_std'] = df['report'].apply(report_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "494226f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['report_std_short'] = df['report_std'].apply(lambda x: x.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e123af09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final          8654\n",
       "Preliminary    4378\n",
       "Condition      2907\n",
       "Other          1565\n",
       "Inspection       54\n",
       "Name: report_std_short, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['report_std_short'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec72029",
   "metadata": {},
   "source": [
    "### Date standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4121c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dates = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if len(row['report_date']) > 0:\n",
    "        final_dates.append(row['report_date'][0])\n",
    "    elif len(row['report_date_2']) > 0:\n",
    "        final_dates.append(row['report_date_2'][0])\n",
    "    elif len(row['date']) > 0:\n",
    "        final_dates.append(row['date'][0])\n",
    "    else:\n",
    "        final_dates.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e2e612da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_dates'] = final_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "048785a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ':' \n",
    "\n",
    "def final_dates_update(x):\n",
    "    return x.replace('data ', 'data: ').replace('date ', 'date: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b18becb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_dates'] = df['final_dates'].apply(final_dates_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b00bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ':' \n",
    "\n",
    "def final_dates_update_2(x):\n",
    "    if ':' in x:    \n",
    "        return x.split(':')[-1].strip()\n",
    "    else:\n",
    "        return x.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5872e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_dates'] = df['final_dates'].apply(final_dates_update_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7ad9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_dates_transform(x):\n",
    "    x = x.replace('/', ' ').replace(', ',' ').replace('.',' ').replace('-',' ')\n",
    "    x = x.replace('  ',' ').replace('  ',' ').replace('  ',' ')\n",
    "    return x.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cefa322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_dates_test'] = df['final_dates'].apply(final_dates_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad086bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_final_dates_test'] = df['final_dates_test'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a4ca56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_and_month_year(x):\n",
    "    day = ''\n",
    "    month = ''\n",
    "    year = ''\n",
    "    if len(x) == 3:\n",
    "        if len(x[0]) == 4 and x[0].isdigit() == True:\n",
    "            year = x[0]\n",
    "            month = x[1]\n",
    "            day = x[2]\n",
    "        else:\n",
    "            year = x[-1]\n",
    "\n",
    "            # miesiac slownie:\n",
    "            if x[1].isalpha() == True:\n",
    "                day = x[0]\n",
    "                month = x[1]\n",
    "\n",
    "            elif x[0].isalpha() == True:\n",
    "                day = x[1]\n",
    "                month = x[0]\n",
    "\n",
    "            # wieksza liczba od 12:\n",
    "            elif x[0].isdigit() and int(x[0]) > 12:\n",
    "                day = x[0]\n",
    "                month = x[1]\n",
    "\n",
    "               # wieksza liczba od 12:\n",
    "            elif x[1].isdigit() and int(x[1]) > 12:\n",
    "                day = x[1]\n",
    "                month = x[0]\n",
    "\n",
    "                \n",
    "                #defaultowe wartosci\n",
    "#             else:\n",
    "#                 day = x[0]\n",
    "#                 month = x[1]\n",
    "        \n",
    "    return day, month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a782b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method include that in US month is first\n",
    "index_houston = []\n",
    "my_dates = []\n",
    "for i, row in df.iterrows():\n",
    "    x = row['final_dates_test']\n",
    "    day = ''\n",
    "    month = ''\n",
    "    year = ''\n",
    "    if len(x) == 3:\n",
    "        if len(x[0]) == 4 and x[0].isdigit() == True:\n",
    "            year = x[0]\n",
    "            month = x[1]\n",
    "            day = x[2]\n",
    "        else:\n",
    "            year = x[-1]\n",
    "\n",
    "            # miesiac slownie:\n",
    "            if x[1].isalpha() == True:\n",
    "                day = x[0]\n",
    "                month = x[1]\n",
    "\n",
    "            elif x[0].isalpha() == True:\n",
    "                day = x[1]\n",
    "                month = x[0]\n",
    "\n",
    "            # wieksza liczba od 12:\n",
    "            elif x[0].isdigit() and int(x[0]) > 12:\n",
    "                day = x[0]\n",
    "                month = x[1]\n",
    "\n",
    "               # wieksza liczba od 12:\n",
    "            elif x[1].isdigit() and int(x[1]) > 12:\n",
    "                day = x[1]\n",
    "                month = x[0]\n",
    "\n",
    "                \n",
    "                #defaultowe wartosci\n",
    "            else:\n",
    "                if 'houston' in row['clean_text']:\n",
    "#                     print(x)\n",
    "                    index_houston.append(i)\n",
    "                    day = x[1]\n",
    "                    month = x[0]\n",
    "                else:\n",
    "                    day = x[0]\n",
    "                    month = x[1]\n",
    "    my_dates.append((day, month, year))\n",
    "#     return day, month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a78d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = [x[0] for x in my_dates]\n",
    "month = [x[1] for x in my_dates]\n",
    "year = [x[2] for x in my_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e719b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_year(x):\n",
    "    x = re.sub(r'\\D+','',x)\n",
    "    if x == '':\n",
    "        return None\n",
    "    if len(x) == 2:\n",
    "        x = '20' + str(x)\n",
    "    if len(x) == 5:\n",
    "        x= str(x)[:4]\n",
    "#     x_final = re.sub(r'\\D+', '', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afe755fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_day(x):\n",
    "    if x == '':\n",
    "        return None\n",
    "    else:\n",
    "        x = re.sub(r'\\D+', '', x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e528d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = day\n",
    "df['month'] = month\n",
    "df['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "753ea00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['std_year'] = df['year'].apply(clean_year)\n",
    "df['std_year'] = df['std_year'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb1fb8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = df['day'].apply(clean_day)\n",
    "df['std_day'] = df['day'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9480fb",
   "metadata": {},
   "source": [
    "### Months standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4cb295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {'1': ['jan', 'gen'],\n",
    "         '2': [r'fe[bv]'],\n",
    "         '3': [r'mar', r'macrh'],\n",
    "         '4': [r'apr'],\n",
    "         '5':[r'ma[ygi]'],\n",
    "         '6':[r'jun', r'giug', r'juin'],\n",
    "          '7':[r'jul', r'lug'],\n",
    "          '8':[r'aug', 'ago', 'aot'],   #to mozna tez dac, ze po prstu ma sie zaczynac na a\n",
    "         '9': [r'se[pt]', r'sptember'],\n",
    "          '10':[r'o[ct]t'],\n",
    "          '11':[r'nov'],\n",
    "          '12':[r'd[ei]c'],\n",
    "          '0': [r'rev', r'soook', r'ago', r'gtg', r'opened', r'cont']\n",
    "         \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca6b2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_month(x):\n",
    "    x = x.strip()\n",
    "    if x.isalpha():\n",
    "#         my_month = ''\n",
    "        for month, patterns in months.items():\n",
    "            my_month = ''\n",
    "            for pattern in patterns:\n",
    "                if len(re.findall(pattern, x)) > 0:\n",
    "                    my_month = month\n",
    "                    return my_month\n",
    "#                 elif len(re.findall(pattern, x)) == 0:\n",
    "#                     return 'Error'\n",
    "    \n",
    "    elif x == '':\n",
    "        return None\n",
    "    \n",
    "    elif x.isdigit() == False:\n",
    "        return '0'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0893fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['std_month'] = df['month'].apply(std_month)\n",
    "df['std_month'] = df['std_month'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a65729",
   "metadata": {},
   "source": [
    "### Data Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "694952fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warning_signes = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    # day_error\n",
    "    if row['std_day'] == 0 or row['std_day'] > 31:\n",
    "        is_warning = True\n",
    "    \n",
    "    # year error\n",
    "    elif row['std_year'] > 2022 or row['std_year'] < 1995:\n",
    "        is_warning = True\n",
    "    else:\n",
    "        is_warning = False\n",
    "        \n",
    "\n",
    "    if row['std_month'] < 1 or row['std_month'] > 12:\n",
    "        is_warning = True\n",
    "#     else:\n",
    "#         is_warning = False\n",
    "        \n",
    "    warning_signes.append(is_warning)\n",
    "\n",
    "\n",
    "\n",
    "df['Date_error'] = warning_signes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f20868a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    17536\n",
       "True        22\n",
       "Name: Date_error, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date_error'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11360496",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 1 iteration and we have such errors:\n",
      "False    17536\n",
      "True        22\n",
      "Name: Date_error, dtype: int64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m             final_dates\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mdf_temp\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_dates\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_dates\n\u001b[0;32m     23\u001b[0m df_temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_dates\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_dates\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(final_dates_update)\n\u001b[0;32m     24\u001b[0m df_temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_dates_test\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_dates\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(final_dates_transform)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_temp' is not defined"
     ]
    }
   ],
   "source": [
    "# ## Correction pipeline\n",
    "# ## This was an attempt to correct Data errors, but since there are only few errors it's better to correct it manualy\n",
    "# attempts = [1, 2, 3]\n",
    "# for i in attempts:\n",
    "#     final_dates = []\n",
    "\n",
    "    \n",
    "#     print(f'This is {i} iteration and we have such errors:')\n",
    "#     print(df['Date_error'].value_counts())\n",
    "    \n",
    "#     for i, row in df.iterrows():\n",
    "#         if row['Date_error'] == True:\n",
    "#             if len(row['report_date']) > 1:\n",
    "#                 final\n",
    "#                 final_dates.append(row['report_date'][1])\n",
    "#             elif len(row['report_date_2']) > 0:\n",
    "#                 final_dates.append(row['report_date_2'][0])\n",
    "#             elif len(row['date']) > 0:\n",
    "#                 final_dates.append(row['date'][0])\n",
    "#             else:\n",
    "#                 final_dates.append('')\n",
    "            \n",
    "#     df_temp['final_dates'] = final_dates\n",
    "#     df_temp['final_dates'] = df_temp['final_dates'].apply(final_dates_update)\n",
    "#     df_temp['final_dates_test'] = df_temp['final_dates'].apply(final_dates_transform)\n",
    "    \n",
    "    \n",
    "#     # this method include that in US month is first\n",
    "#     index_houston = []\n",
    "#     my_dates = []\n",
    "#     for i, row in df_temp.iterrows():\n",
    "#         x = row['final_dates_test']\n",
    "#         day = ''\n",
    "#         month = ''\n",
    "#         year = ''\n",
    "#         if len(x) == 3:\n",
    "#             if len(x[0]) == 4 and x[0].isdigit() == True:\n",
    "#                 year = x[0]\n",
    "#                 month = x[1]\n",
    "#                 day = x[2]\n",
    "#             else:\n",
    "#                 year = x[-1]\n",
    "\n",
    "#                 # miesiac slownie:\n",
    "#                 if x[1].isalpha() == True:\n",
    "#                     day = x[0]\n",
    "#                     month = x[1]\n",
    "\n",
    "#                 elif x[0].isalpha() == True:\n",
    "#                     day = x[1]\n",
    "#                     month = x[0]\n",
    "\n",
    "#                 # wieksza liczba od 12:\n",
    "#                 elif x[0].isdigit() and int(x[0]) > 12:\n",
    "#                     day = x[0]\n",
    "#                     month = x[1]\n",
    "\n",
    "#                    # wieksza liczba od 12:\n",
    "#                 elif x[1].isdigit() and int(x[1]) > 12:\n",
    "#                     day = x[1]\n",
    "#                     month = x[0]\n",
    "\n",
    "\n",
    "#                     #defaultowe wartosci\n",
    "#                 else:\n",
    "#                     if 'houston' in row['clean_text']:\n",
    "#     #                     print(x)\n",
    "#                         index_houston.append(i)\n",
    "#                         day = x[1]\n",
    "#                         month = x[0]\n",
    "#                     else:\n",
    "#                         day = x[0]\n",
    "#                         month = x[1]\n",
    "#         my_dates.append((day, month, year))\n",
    "        \n",
    "#     day = [x[0] for x in my_dates]\n",
    "#     month = [x[1] for x in my_dates]\n",
    "#     year = [x[2] for x in my_dates]\n",
    "    \n",
    "#     df_temp['day'] = day\n",
    "#     df_temp['month'] = month\n",
    "#     df_temp['year'] = year\n",
    "    \n",
    "#     df_temp['day'] = df_temp['day'].apply(clean_day)\n",
    "#     df_temp['std_day'] = df_temp['day'].astype(float)\n",
    "#     df_temp['std_year'] = df_temp['year'].apply(clean_year)\n",
    "#     df_temp['std_year'] = df_temp['std_year'].astype(float)\n",
    "#     df_temp['std_month'] = df_temp['month'].apply(std_month)\n",
    "#     df_temp['std_month'] = df_temp['std_month'].astype(float)\n",
    "#     warning_signes = []\n",
    "\n",
    "#     for i, row in df_temp.iterrows():\n",
    "\n",
    "#         # day_error\n",
    "#         if row['std_day'] == 0 or row['std_day'] > 31:\n",
    "#             is_warning = True\n",
    "\n",
    "#         # year error\n",
    "#         elif row['std_year'] > 2022 or row['std_year'] < 1995:\n",
    "#             is_warning = True\n",
    "#         else:\n",
    "#             is_warning = False\n",
    "\n",
    "\n",
    "#         if row['std_month'] < 1 or row['std_month'] > 12:\n",
    "#             is_warning = True\n",
    "#     #     else:\n",
    "#     #         is_warning = False\n",
    "\n",
    "#         warning_signes.append(is_warning)\n",
    "\n",
    "\n",
    "\n",
    "#     df_temp['Date_error'] = warning_signes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "48f8b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st = df[['name', 'source', 'clean_text', 'SN_checked_final', 'job', 'report_std_short', 'std_year', 'std_month', 'std_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "acadd2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st.to_csv('Tagged_July_25_22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129c5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee3bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
